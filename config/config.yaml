region: us-west-2
s3_bucket: voicebot-matrix-hackathon  # Replace with your bucket name
qa_csv: data/qa_dataset.csv
test_csv: data/test.csv
transcriptions_csv: data/transcriptions.csv
output_csv: output/output.csv

# AWS Services Configuration
transcribe:
  language_code: hi-IN
  identify_language: true
  sample_rate: 16000
  channels: 1

polly:
  voice_id: Joanna
  engine: neural

# LLM Configuration
llm:
  provider: bedrock
  model_id: anthropic.claude-3-sonnet-20240229-v1:0
  temperature: 0.7
  max_tokens: 500

# Response Generation
response:
  fuzzy_match_threshold: 80  # minimum score for fuzzy matching
  use_llm_fallback: true     # whether to use LLM when no good match found
  max_context_window: 5      # maximum number of conversation turns to include in context
  semantic_similarity_threshold: 0.50  # threshold for semantic similarity matching

# Memory Configuration
memory:
  use_vector_memory: False  # disable vector-based memory (using recency only)
  relevance_threshold: 0.65  # minimum similarity score for vector memory matches
  recent_limit: 3            # number of recent conversations to include in context
  semantic_limit: 3          # number of semantically relevant conversations to include
  memory_weight: 0.4         # weight for memory relevance in ranking (0-1)
  recency_weight: 0.4        # weight for recency in ranking (0-1)
  importance_weight: 0.2     # weight for importance in ranking (0-1)

# RAG Configuration  
rag:
  top_k_retrieval: 3         # number of top matches to retrieve from FAISS
